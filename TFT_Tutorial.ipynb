{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b095ee96-685f-4394-8246-8616f5e5dd47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TFT Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecafc74a-ba49-470e-bc67-0a4f8e4be411",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba77096f-211c-4584-a1a3-cbe6adb0b80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pkg_resources' from 'D:\\\\Users\\\\shini\\\\anaconda3\\\\envs\\\\tf2_py37\\\\lib\\\\site-packages\\\\pkg_resources\\\\__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import importlib\n",
    "importlib.reload(pkg_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84493a24-27eb-4222-873a-35518eabaacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "from tfx_bsl.public import tfxio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d727cf-c844-4ec7-a73f-8ec528b375b4",
   "metadata": {},
   "source": [
    "### 2. Preprocessing Function Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0ad9cd-f646-4b1e-809c-5a0b9121517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(inputs):\n",
    "  x = inputs['x']\n",
    "  y = inputs['y']\n",
    "  s = inputs['s']\n",
    "  x_centered = x - tft.mean(x)\n",
    "  y_normalized = tft.scale_to_0_1(y)\n",
    "  s_integerized = tft.compute_and_apply_vocabulary(s)\n",
    "  x_centered_times_y_normalized = x_centered * y_normalized\n",
    "  return {\n",
    "      'x_centered': x_centered,\n",
    "      'y_normalized': y_normalized,\n",
    "      'x_centered_times_y_normalized': x_centered_times_y_normalized,\n",
    "      's_integerized': s_integerized\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "018b6a32-1f00-42f8-b51d-157fdff4a669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shini\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_transform\\tf_utils.py:326: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shini\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_transform\\tf_utils.py:326: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['D:\\\\Users\\\\shini\\\\anaconda3\\\\envs\\\\tf2_py37\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\shini\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-0f2ff9bf-e21c-4f68-9c00-7d2d0d3b0681.json']\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmp83v96zln\\tftransform_tmp\\809def6429b2481596facf10aea5ebd2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmp83v96zln\\tftransform_tmp\\809def6429b2481596facf10aea5ebd2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmp83v96zln\\tftransform_tmp\\1ae55617b6cc44218edab710c7cdd400\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmp83v96zln\\tftransform_tmp\\1ae55617b6cc44218edab710c7cdd400\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    }
   ],
   "source": [
    "raw_data = [\n",
    "    {'x': 1, 'y': 1, 's': 'hello'},\n",
    "    {'x': 2, 'y': 2, 's': 'world'},\n",
    "    {'x': 3, 'y': 3, 's': 'hello'}\n",
    "]\n",
    "\n",
    "raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
    "    schema_utils.schema_from_feature_spec({\n",
    "        'y': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
    "        's': tf.io.FixedLenFeature([], tf.string),\n",
    "    }))\n",
    "\n",
    "with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "  transformed_dataset, transform_fn = (\n",
    "      (raw_data, raw_data_metadata) |\n",
    "      tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60dbb19a-488a-4bca-8321-fee5aee3e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data, transformed_metadata = transformed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67525a5e-22c3-4299-915f-cf6699afaa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'s_integerized': 0,\n",
       "  'x_centered': -1.0,\n",
       "  'x_centered_times_y_normalized': -0.0,\n",
       "  'y_normalized': 0.0},\n",
       " {'s_integerized': 1,\n",
       "  'x_centered': 0.0,\n",
       "  'x_centered_times_y_normalized': 0.0,\n",
       "  'y_normalized': 0.5},\n",
       " {'s_integerized': 0,\n",
       "  'x_centered': 1.0,\n",
       "  'x_centered_times_y_normalized': 1.0,\n",
       "  'y_normalized': 1.0}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af3ac24c-b45a-4cb7-b67c-ee3ab5b4a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = (raw_data, raw_data_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a32658b1-9ece-4793-9185-54d163af5622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['D:\\\\Users\\\\shini\\\\anaconda3\\\\envs\\\\tf2_py37\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\shini\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-0f2ff9bf-e21c-4f68-9c00-7d2d0d3b0681.json']\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpw2mvjb5k\\tftransform_tmp\\770ae25549bf45b9b45ebc2024ebd1e0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpw2mvjb5k\\tftransform_tmp\\770ae25549bf45b9b45ebc2024ebd1e0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpw2mvjb5k\\tftransform_tmp\\962e3bad33a44e6389f0825120df2fbe\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpw2mvjb5k\\tftransform_tmp\\962e3bad33a44e6389f0825120df2fbe\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    }
   ],
   "source": [
    "with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "  transformed_data, transform_fn = (\n",
    "      my_data | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d856ca0a-61bc-47c0-9b63-e7d038a3c145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['D:\\\\Users\\\\shini\\\\anaconda3\\\\envs\\\\tf2_py37\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\shini\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-0f2ff9bf-e21c-4f68-9c00-7d2d0d3b0681.json']\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpndipxsjo\\tftransform_tmp\\b8a8a49af8d04003ab6a25a4a6444998\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpndipxsjo\\tftransform_tmp\\b8a8a49af8d04003ab6a25a4a6444998\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpndipxsjo\\tftransform_tmp\\2911dd37058e4c798606152484def1be\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpndipxsjo\\tftransform_tmp\\2911dd37058e4c798606152484def1be\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['D:\\\\Users\\\\shini\\\\anaconda3\\\\envs\\\\tf2_py37\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\shini\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-0f2ff9bf-e21c-4f68-9c00-7d2d0d3b0681.json']\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    }
   ],
   "source": [
    "with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "  transform_fn = my_data | tft_beam.AnalyzeDataset(preprocessing_fn)\n",
    "  transformed_data = (my_data, transform_fn) | tft_beam.TransformDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d5b9fa9-3a81-4dbb-b847-ed84043af5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
    "      schema_utils.schema_from_feature_spec({\n",
    "        's': tf.io.FixedLenFeature([], tf.string),\n",
    "        'y': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14256852-dfde-4705-b620-1947aaa8c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "raw_data = [\n",
    "    pa.record_batch(\n",
    "    data=[\n",
    "        pa.array([[1], [2], [3]], pa.list_(pa.float32())),\n",
    "        pa.array([[1], [2], [3]], pa.list_(pa.float32())),\n",
    "        pa.array([['hello'], ['world'], ['hello']], pa.list_(pa.binary())),\n",
    "    ],\n",
    "    names=['x', 'y', 's'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034b77c5-d8c7-40c2-8669-808108781354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "tensor_representation = {\n",
    "    'x': text_format.Parse(\n",
    "        \"\"\"dense_tensor { column_name: \"col1\" shape { dim { size: 2 } } }\"\"\",\n",
    "        schema_pb2.TensorRepresentation())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f75ef359-f07f-4ca4-a429-2809bcbcdd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data_file = \"adult.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "889a8dc2-b61d-43c0-8bbd-0cda3a93b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDERED_CSV_COLUMNS = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'label'\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURE_KEYS = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "]\n",
    "\n",
    "NUMERIC_FEATURE_KEYS = [\n",
    "    'age',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'education-num',\n",
    "]\n",
    "\n",
    "LABEL_KEY = 'label'\n",
    "\n",
    "RAW_DATA_FEATURE_SPEC = dict(\n",
    "    [(name, tf.io.FixedLenFeature([], tf.string))\n",
    "     for name in CATEGORICAL_FEATURE_KEYS] +\n",
    "    [(name, tf.io.FixedLenFeature([], tf.float32))\n",
    "     for name in NUMERIC_FEATURE_KEYS] +\n",
    "    [(LABEL_KEY, tf.io.FixedLenFeature([], tf.string))]\n",
    ")\n",
    "\n",
    "SCHEMA = tft.tf_metadata.dataset_metadata.DatasetMetadata(\n",
    "    tft.tf_metadata.schema_utils.schema_from_feature_spec(RAW_DATA_FEATURE_SPEC)).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6e88f35-05f7-45cc-b23b-771996738eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country   label  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(train_data_file, names = ORDERED_CSV_COLUMNS).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bae92778-e17c-4802-978c-92958649e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx_bsl.public import tfxio\n",
    "from tfx_bsl.coders.example_coder import RecordBatchToExamples\n",
    "\n",
    "import apache_beam as beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81d2f2d5-bb71-4d13-b349-d54d4810439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = beam.Pipeline()\n",
    "\n",
    "csv_tfxio = tfxio.BeamRecordCsvTFXIO(\n",
    "    physical_format='text', column_names=ORDERED_CSV_COLUMNS, schema=SCHEMA)\n",
    "\n",
    "raw_data = (\n",
    "    pipeline\n",
    "    | 'ReadTrainData' >> beam.io.ReadFromText(\n",
    "        train_data_file, coder=beam.coders.BytesCoder())\n",
    "    | 'FixCommasTrainData' >> beam.Map(\n",
    "        lambda line: line.replace(b', ', b','))\n",
    "    | 'DecodeTrainData' >> csv_tfxio.BeamSource())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8b2df9b-a778-43c8-9e18-fe5eb3b5ae56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PCollection[[26]: DecodeTrainData/RawRecordToRecordBatch/CollectRecordBatchTelemetry/ProfileRecordBatches.None] at 0x1808c71efc8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbd7d4dc-6875-4bc7-b34c-c2e3739ab5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_tfxio = tfxio.CsvTFXIO(train_data_file,\n",
    "                           telemetry_descriptors=[], #???\n",
    "                           column_names=ORDERED_CSV_COLUMNS,\n",
    "                           schema=SCHEMA)\n",
    "\n",
    "p2 = beam.Pipeline()\n",
    "raw_data_2 = p2 | 'TFXIORead' >> csv_tfxio.BeamSource()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cf013db-d131-48b8-af8d-b73c46e12f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OOV_BUCKETS = 1\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "  \"\"\"Preprocess input columns into transformed columns.\"\"\"\n",
    "  # Since we are modifying some features and leaving others unchanged, we\n",
    "  # start by setting `outputs` to a copy of `inputs.\n",
    "  outputs = inputs.copy()\n",
    "\n",
    "  # Scale numeric columns to have range [0, 1].\n",
    "  for key in NUMERIC_FEATURE_KEYS:\n",
    "    outputs[key] = tft.scale_to_0_1(outputs[key])\n",
    "\n",
    "  # For all categorical columns except the label column, we generate a\n",
    "  # vocabulary but do not modify the feature.  This vocabulary is instead\n",
    "  # used in the trainer, by means of a feature column, to convert the feature\n",
    "  # from a string to an integer id.\n",
    "  for key in CATEGORICAL_FEATURE_KEYS:\n",
    "    outputs[key] = tft.compute_and_apply_vocabulary(\n",
    "        tf.strings.strip(inputs[key]),\n",
    "        num_oov_buckets=NUM_OOV_BUCKETS,\n",
    "        vocab_filename=key)\n",
    "\n",
    "  # For the label column we provide the mapping from string to index.\n",
    "  with tf.init_scope():\n",
    "    # `init_scope` - Only initialize the table once.\n",
    "    initializer = tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=['>50K', '<=50K'],\n",
    "        values=tf.cast(tf.range(2), tf.int64),\n",
    "        key_dtype=tf.string,\n",
    "        value_dtype=tf.int64)\n",
    "    table = tf.lookup.StaticHashTable(initializer, default_value=-1)\n",
    "\n",
    "  outputs[LABEL_KEY] = table.lookup(outputs[LABEL_KEY])\n",
    "\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98e0d257-cd3b-411e-8f86-2b2f7fc86aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = (raw_data, csv_tfxio.TensorAdapterConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0eb23e84-70f2-471e-8639-e202c3cf8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.path.join('D:\\Study\\ML\\ML_Study_with_Jo\\TFT\\working_dir')\n",
    "with tft_beam.Context(temp_dir=working_dir):\n",
    "  transformed_dataset, transform_fn = (\n",
    "      raw_dataset | tft_beam.AnalyzeAndTransformDataset(\n",
    "          preprocessing_fn, output_record_batches=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "815b5814-735e-45ff-9617-6588b829607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join('D:\\Study\\ML\\ML_Study_with_Jo\\TFT\\output_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baf33b60-d887-45cb-8970-e577a4280aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data, _ = transformed_dataset\n",
    "\n",
    "_ = (\n",
    "    transformed_data\n",
    "    | 'EncodeTrainData' >>\n",
    "    beam.FlatMapTuple(lambda batch, _: RecordBatchToExamples(batch))\n",
    "    | 'WriteTrainData' >> beam.io.WriteToTFRecord(\n",
    "        os.path.join(output_dir , 'transformed.tfrecord')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "823867c2-33d9-407c-bfa7-15c23709bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = (\n",
    "    transform_fn\n",
    "    | 'WriteTransformFn' >> tft_beam.WriteTransformFn(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48f9308a-2a18-4635-a00f-9b7dadfcfcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpgzch6cio\\tftransform_tmp\\ffa5ad74427c4bff86a2159e90c9a3fa\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpgzch6cio\\tftransform_tmp\\ffa5ad74427c4bff86a2159e90c9a3fa\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Study\\ML\\ML_Study_with_Jo\\TFT\\working_dir\\tftransform_tmp\\d33f2dbe46204d638a78442cad63ca64\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Study\\ML\\ML_Study_with_Jo\\TFT\\working_dir\\tftransform_tmp\\d33f2dbe46204d638a78442cad63ca64\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpgzch6cio\\tftransform_tmp\\abd312f83b5a4b4f967ddbbb72b10d7e\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shini\\AppData\\Local\\Temp\\tmpgzch6cio\\tftransform_tmp\\abd312f83b5a4b4f967ddbbb72b10d7e\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Study\\ML\\ML_Study_with_Jo\\TFT\\working_dir\\tftransform_tmp\\1076f8f41dc94546bbebcfe29c76ca9d\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Study\\ML\\ML_Study_with_Jo\\TFT\\working_dir\\tftransform_tmp\\1076f8f41dc94546bbebcfe29c76ca9d\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    }
   ],
   "source": [
    "result = pipeline.run().wait_until_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dbc0e8-6788-4da0-a3ba-7c1e1f06d85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
